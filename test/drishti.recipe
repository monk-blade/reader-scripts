#!/usr/bin/env python
# vim:fileencoding=utf-8
import re
from calibre.web.feeds.news import BasicNewsRecipe, classes


class DrishtiIAS(BasicNewsRecipe):
    title          = 'DrishtiIAS'
    description = 'DrishtiIAS UPSC Feed'
    __author__ = 'Arpan'
    language = 'hi'
    encoding = 'utf-8'
#    oldest_article = 2
    max_articles_per_feed = 7
    no_stylesheets = True
    remove_attributes = ['style', 'height', 'width']
    ignore_duplicate_articles = {'url'}
    compress_news_images = True
    compress_news_images_auto_size = 10
    scale_news_images = (800, 800)
    # remove_tags_before = [
    #     classes('article-list')
    # ]
    keep_only_tags = [
        classes('article-list')
    ]
    remove_tags = [
        classes('category archive updates desktop-ad-banner mobile-ad-banner list-title next-post btn-group disqus_thread close'),
        #dict(name='source'),
    ]

    def parse_index(self):
        url = 'https://www.drishtiias.com/hindi/current-affairs-news-analysis-editorials'
        soup = self.index_to_soup(url)
        articles = soup.select(".box-hide a")
#        articles = soup.find_all('div', class_='card-info-wrapper')
        feed = []
        #print(articles)
        for i in articles:
            #print("This is ilevel :" + i['href'])
            article = {}
            editorial_link = re.match(
                r".*news-editorials.*", i['href'], re.IGNORECASE
            )
            if editorial_link:
                article['url'] = i['href']
                print('Article URL : ' + article['url'])
                article['title'] = i.find('span').text.strip()
                print('Article Title : ' + article['title'])
#               author = i.find('p', class_='card-byline')
                article['author'] = 'Team DrishtiIAS'
                feed.append(article)
            #regexp = re.compile('.*news-editorials.*')
            #tmp_url = regexp.findall(i['href'])
            #print(tmp_url)
            #article['url'] = i['href']
            #print('Article URL : ' + article['url'])
            #if(tmp_url):
            #    article['url'] = regexp.findall(i['href'])
#            article['url'] = i.find('a')['href']
#            if article['url'].startswith('/'):
#                article['url'] = 'https://cooking.nytimes.com' + article['url']


        return [('Editorials', feed)]


# for link in soup.select(".box-toggle:nth-child(2) .box-slide , .box-hide a"):
#   regexp = re.compile('.*news-editorials.*')
#   #spacn = link.find_all("href", string=re.compile("August"))
#   #print(spacn)
#   editorial_url = regexp.findall(link['href'])
#   if(editorial_url):
#     print(editorial_url)